Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

Load or create a dataset
# For demonstration, we'll generate a synthetic dataset
np.random.seed(42)
data = np.random.rand(100, 5)  # 100 samples, 5 features

# Convert to DataFrame for better visualization
df = pd.DataFrame(data, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])

 Standardize the dataset
# PCA is affected by the scale of the data, so we need to standardize it
scaler = StandardScaler()
scaled_data = scaler.fit_transform(df)

 Apply PCA to reduce dimensionality
# Let's reduce the dataset to 2 principal components
pca = PCA(n_components=2)
pca_data = pca.fit_transform(scaled_data)

 Visualize or inspect the reduced data
# Convert the PCA result back to a DataFrame
pca_df = pd.DataFrame(pca_data, columns=['PC1', 'PC2'])

# Plot the PCA-reduced data
plt.figure(figsize=(8, 6))
plt.scatter(pca_df['PC1'], pca_df['PC2'], c='blue', marker='o')
plt.title('PCA Dimensionality Reduction')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.grid(True)
plt.show()
